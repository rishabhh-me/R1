{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 0: Setup & Sanity Check\n",
    "\n",
    "This notebook implements the minimal end-to-end loop for the Language-As-Memory Continual RL project.\n",
    "\n",
    "**Goals:**\n",
    "1. Setup Environment (install dependencies).\n",
    "2. Load Config & Components (Env, Planner, Agent).\n",
    "3. Run a single episode loop: State -> LLM -> Subgoal -> PPO Agent.\n",
    "\n",
    "**Note:** Ensure you are running on a GPU runtime (T4) if you want to test the real Phi-2 model. Otherwise, the system will default to `MockPlanner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup & Installation\n",
    "# Uncomment and run if you are running this in Colab and haven't cloned the repo yet.\n",
    "\n",
    "# !git clone https://github.com/YOUR_USERNAME/language-as-memory-continual-rl.git\n",
    "# %cd language-as-memory-continual-rl\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "!pip install gymnasium minigrid stable-baselines3 transformers accelerate bitsandbytes peft trl tensorboard pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Imports & Configuration\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "# Ensure src is in path\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "from src.utils.logger import ExperimentLogger\n",
    "from src.utils.subgoal_parser import parse_subgoal\n",
    "from src.llm.planner import get_planner\n",
    "from src.envs.wrappers import SubgoalWrapper\n",
    "from src.ppo.sb3_agent import create_agent\n",
    "from src.utils.seeding import set_global_seeds\n",
    "\n",
    "# Load Config\n",
    "with open(\"src/configs/default_config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set Global Seeds\n",
    "set_global_seeds(config['experiment']['seed'])\n",
    "\n",
    "print(f\"Config Loaded. Device: {config['experiment']['device']}\")\n",
    "print(f\"Environment: {config['env']['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Initialize Components\n",
    "\n",
    "# 1. Environment\n",
    "env = gym.make(config['env']['id'], render_mode=\"rgb_array\")\n",
    "env = SubgoalWrapper(env)\n",
    "\n",
    "# 2. Planner (LLM or Mock)\n",
    "# This will load Phi-2 bitsandbytes if GPU is available, otherwise MockPlanner\n",
    "planner = get_planner(config)\n",
    "\n",
    "# 3. PPO Agent\n",
    "agent = create_agent(env, config)\n",
    "\n",
    "print(\"Components Initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3.5 Train Agent (Bootstrap)\n",
    "# Train the agent briefly so it learns to follow basic commands.\n",
    "# We set a default subgoal 'Pick up key' or 'Go to goal' to train a basic skill.\n",
    "\n",
    "# Set subgoal for training: Pick up the key (ID 2)\n",
    "env.set_subgoal((\"pick\", \"yellow\", \"key\"), 2)\n",
    "\n",
    "print(f\"Training agent for {config['rl']['total_timesteps']} steps on 'Pick up key'...\")\n",
    "agent.learn(total_timesteps=config['rl']['total_timesteps'])\n",
    "print(\"Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Execution Loop (Single Episode)\n",
    "\n",
    "obs, info = env.reset(seed=config['experiment']['seed'])\n",
    "state_text = env.get_text_description()\n",
    "print(f\"[State]: {state_text}\")\n",
    "\n",
    "# Generate Subgoal\n",
    "print(\"Querying Planner...\")\n",
    "subgoal_text = planner.generate_subgoal(state_text)\n",
    "print(f\"[Planner Output]: {subgoal_text}\")\n",
    "\n",
    "# Parse Subgoal\n",
    "subgoal_tuple, subgoal_id = parse_subgoal(subgoal_text)\n",
    "print(f\"[Parsed]: {subgoal_tuple} -> ID: {subgoal_id}\")\n",
    "\n",
    "# Update Environment with Subgoal\n",
    "env.set_subgoal(subgoal_tuple, subgoal_id)\n",
    "\n",
    "# Execute Agent Steps\n",
    "max_steps = 100 # Increased from 20 to give time to reach target\n",
    "total_reward = 0\n",
    "\n",
    "print(f\"Executing agent for up to {max_steps} steps...\")\n",
    "\n",
    "for step in range(max_steps):\n",
    "    action, _ = agent.predict(obs, deterministic=False)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    if info.get('subgoal_completed', False):\n",
    "        print(f\"Subgoal completed at step {step+1}!\")\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print(f\"Episode finished at step {step+1}. Total Reward: {total_reward}\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"Max steps reached. Total Reward: {total_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
